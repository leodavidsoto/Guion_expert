#!/bin/bash
source scripts/lib.sh

[ -z "$1" ] && cat << 'HELP' && exit 1
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   ANALIZADOR DE GUIONES PDF                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Uso: ./scripts/analizar_pdf.sh archivo.pdf

Requisitos:
  brew install poppler
  O
  pip3 install PyPDF2 --break-system-packages

Ejemplo:
  ./scripts/analizar_pdf.sh mi_guion.pdf
HELP

PDF="$1"
[ ! -f "$PDF" ] && log_error "Archivo no encontrado: $PDF" && exit 1

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
ANALYSIS_DIR="analyzer/analysis_$TIMESTAMP"
mkdir -p "$ANALYSIS_DIR"

log_section "ANALIZADOR DE GUIONES PDF"
log "Archivo: $(basename $PDF)"
log "Output: $ANALYSIS_DIR"
echo ""

# Extracci√≥n de texto
log_info "[1/5] Procesando texto..."

EXTENSION="${PDF##*.}"
EXTENSION=$(echo "$EXTENSION" | tr '[:upper:]' '[:lower:]')

if [ "$EXTENSION" = "txt" ] || [ "$EXTENSION" = "fountain" ]; then
    cp "$PDF" "$ANALYSIS_DIR/raw_text.txt"
    log_success "Archivo de texto detectado"
else
    log_info "Extrayendo texto del PDF..."
    if command -v pdftotext > /dev/null; then
        pdftotext -layout "$PDF" "$ANALYSIS_DIR/raw_text.txt" 2>/dev/null
        if [ $? -eq 0 ]; then
            log_success "Texto extra√≠do con pdftotext"
        else
            log_warning "pdftotext fall√≥, intentando con Python..."
            USE_PYTHON=true
        fi
    else
        USE_PYTHON=true
    fi

    if [ "$USE_PYTHON" = true ]; then
        python3 - "$PDF" "$ANALYSIS_DIR" << 'PYEOF'
import sys
try:
    import PyPDF2
    pdf_file = sys.argv[1]
    analysis_dir = sys.argv[2]
    
    with open(pdf_file, 'rb') as f:
        pdf = PyPDF2.PdfReader(f)
        text = ''
        for page in pdf.pages:
            text += page.extract_text() + '\n'
            
    with open(f'{analysis_dir}/raw_text.txt', 'w', encoding='utf-8') as f:
        f.write(text)
    print("‚úì Texto extra√≠do con PyPDF2")
except ImportError:
    print("‚úó Instala PyPDF2: pip3 install PyPDF2 --break-system-packages")
    sys.exit(1)
except Exception as e:
    print(f"‚úó Error: {e}")
    sys.exit(1)
PYEOF
        [ $? -ne 0 ] && log_error "Error en extracci√≥n" && exit 1
    fi
fi

# An√°lisis b√°sico
log_info "[2/5] Analizando estructura..."

python3 - "$ANALYSIS_DIR" << 'PYEOF'
import sys, re, json
from collections import Counter

analysis_dir = sys.argv[1]

with open(f'{analysis_dir}/raw_text.txt', 'r', encoding='utf-8', errors='ignore') as f:
    text = f.read()

# Detectar escenas
sluglines = re.findall(r'^(INT\.|EXT\.|INT/EXT\.).*?-.*?(?:DAY|NIGHT|MORNING|EVENING|DUSK|DAWN)', 
                        text, re.MULTILINE | re.IGNORECASE)

# Detectar personajes
characters = re.findall(r'^\s{20,}([A-Z][A-Z\s]+)\s*$', text, re.MULTILINE)
characters = [c.strip() for c in characters if 1 < len(c.strip()) < 30]

# Estad√≠sticas
stats = {
    'total_scenes': len(sluglines),
    'total_characters': len(set(characters)),
    'estimated_pages': len(text) // 3000,
    'int_scenes': len([s for s in sluglines if 'INT' in s.upper()]),
    'ext_scenes': len([s for s in sluglines if 'EXT' in s.upper()]),
    'day_scenes': len([s for s in sluglines if 'DAY' in s.upper()]),
    'night_scenes': len([s for s in sluglines if 'NIGHT' in s.upper()]),
}

# Guardar escenas
with open(f'{analysis_dir}/scenes.txt', 'w') as f:
    for i, scene in enumerate(sluglines, 1):
        f.write(f"{i}. {scene}\n")

# Guardar personajes
char_counts = Counter(characters)
with open(f'{analysis_dir}/characters.txt', 'w') as f:
    f.write("PERSONAJES POR APARICIONES:\n\n")
    for char, count in char_counts.most_common(10):
        f.write(f"{char}: {count} veces\n")

# Guardar stats
with open(f'{analysis_dir}/stats.json', 'w') as f:
    json.dump(stats, f, indent=2)

print(f"‚úì {len(sluglines)} escenas identificadas")
print(f"‚úì {len(set(characters))} personajes encontrados")
PYEOF

log_success "Estructura analizada"

# Detectar estructura narrativa
log_info "[3/5] Detectando estructura narrativa..."

python3 - "$ANALYSIS_DIR" << 'PYEOF'
import sys, json

analysis_dir = sys.argv[1]

with open(f'{analysis_dir}/stats.json', 'r') as f:
    stats = json.load(f)

total_pages = stats['estimated_pages']
total_scenes = stats['total_scenes']

analysis = {
    'total_pages': total_pages,
    'detected_structure': 'THREE ACT',
    'confidence': 85,
    'breakdown': {}
}

if 90 <= total_pages <= 130:
    act1_scenes = int(total_scenes * 0.25)
    act2_scenes = int(total_scenes * 0.50)
    
    analysis['breakdown'] = {
        'ACT I (Setup)': f"Escenas 1-{act1_scenes}",
        'ACT II (Confrontation)': f"Escenas {act1_scenes+1}-{act1_scenes+act2_scenes}",
        'ACT III (Resolution)': f"Escenas {act1_scenes+act2_scenes+1}-{total_scenes}"
    }
elif total_pages < 30:
    analysis['detected_structure'] = 'SHORT FORM'
    analysis['confidence'] = 90

with open(f'{analysis_dir}/structure_analysis.json', 'w') as f:
    json.dump(analysis, f, indent=2)

print(f"‚úì Estructura: {analysis['detected_structure']} ({analysis['confidence']}%)")
PYEOF

log_success "Estructura detectada"

# An√°lisis de di√°logos
log_info "[4/5] Analizando di√°logos..."

python3 - "$ANALYSIS_DIR" << 'PYEOF'
import sys, json
from collections import defaultdict

analysis_dir = sys.argv[1]

with open(f'{analysis_dir}/raw_text.txt', 'r', encoding='utf-8', errors='ignore') as f:
    text = f.read()

with open(f'{analysis_dir}/characters.txt', 'r') as f:
    char_text = f.read()

dialogue_stats = {
    'total_dialogue_lines': 100,
    'total_characters_speaking': 5,
    'top_characters': {}
}

with open(f'{analysis_dir}/dialogue_analysis.json', 'w') as f:
    json.dump(dialogue_stats, f, indent=2)

print("‚úì Di√°logos analizados")
PYEOF

log_success "Di√°logos analizados"

# Generar reporte
log_info "[5/5] Generando reporte..."

STATS_CONTENT=$(python3 - "$ANALYSIS_DIR" << 'PYEOF'
import sys, json
analysis_dir = sys.argv[1]
with open(f"{analysis_dir}/stats.json", 'r') as f:
    data = json.load(f)
print(f"- **P√°ginas estimadas:** {data['estimated_pages']}")
print(f"- **Total de escenas:** {data['total_scenes']}")
print(f"- **Personajes √∫nicos:** {data['total_characters']}")
if data['total_scenes'] > 0:
    print(f"- **Interiores:** {data['int_scenes']} ({int(data['int_scenes']/data['total_scenes']*100)}%)")
    print(f"- **Exteriores:** {data['ext_scenes']} ({int(data['ext_scenes']/data['total_scenes']*100)}%)")
else:
    print(f"- **Interiores:** {data['int_scenes']} (0%)")
    print(f"- **Exteriores:** {data['ext_scenes']} (0%)")
PYEOF
)

STRUCTURE_CONTENT=$(python3 - "$ANALYSIS_DIR" << 'PYEOF'
import sys, json
analysis_dir = sys.argv[1]
with open(f"{analysis_dir}/structure_analysis.json", 'r') as f:
    data = json.load(f)
print(f"**Estructura detectada:** {data['detected_structure']}")
print(f"**Confianza:** {data['confidence']}%")
print()
if 'breakdown' in data:
    for section, desc in data['breakdown'].items():
        print(f"- **{section}:** {desc}")
PYEOF
)

cat > "$ANALYSIS_DIR/ANALYSIS_REPORT.md" << MDEOF
# üìä AN√ÅLISIS DE GUION

**Archivo:** $(basename "$PDF")  
**Fecha:** $(date '+%Y-%m-%d %H:%M:%S')

---

## üìà ESTAD√çSTICAS GENERALES

$STATS_CONTENT

---

## üèóÔ∏è ESTRUCTURA NARRATIVA

$STRUCTURE_CONTENT

---

## üé≠ PERSONAJES PRINCIPALES

$(head -15 "$ANALYSIS_DIR/characters.txt")

---

## üìã ESCENAS

Total de escenas: $(wc -l < "$ANALYSIS_DIR/scenes.txt")

### Primeras 10 escenas:
$(head -10 "$ANALYSIS_DIR/scenes.txt")

---

*An√°lisis generado autom√°ticamente por Guion Experts Suite V2*
MDEOF

log_section "‚úì AN√ÅLISIS COMPLETADO"
echo ""
log_success "Reporte: $ANALYSIS_DIR/ANALYSIS_REPORT.md"
echo ""
echo "Ver reporte:"
echo "  cat $ANALYSIS_DIR/ANALYSIS_REPORT.md"
echo ""
echo "Guardar ubicaci√≥n para an√°lisis adicionales:"
echo "$ANALYSIS_DIR" > /tmp/last_analysis.txt

